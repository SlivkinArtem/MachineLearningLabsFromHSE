{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQZun38W12kD"
      },
      "source": [
        "# KNN, рак и спам\n",
        "__Суммарное количество баллов: 12__\n",
        "\n",
        "В этом домашнем задании Вам предлагается при помощи классификации методом k ближайших соседей научиться отличать тип опухоли в организме, а так же определять сообщения со спамом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksl6uyLJ12kK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import copy\n",
        "import pandas\n",
        "from typing import NoReturn, Tuple, List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKFp_fBM12kM"
      },
      "source": [
        "### Задание 1 (1 балл)\n",
        "Для начала работы нам необходимо научиться читать набор данных. Всего мы будем работать с двумя наборами данных.\n",
        "\n",
        "__Cancer.csv__ - выборка данных о пациентах с доброкачественными и злокачественными опухолями. Задача - научиться их отличать.\n",
        "\n",
        "__Spam.csv__ - набор данных большего размера. Он содержит некоторую статистику по сообщениям, а так же метку, является ли сообщение спамом. Задача - научиться автоматически отличать спам от обычных сообщений.\n",
        "\n",
        "Реализуйте методы `read_cancer_dataset` и `read_spam_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`. Набор данных должен быть упорядочен случайно, т.е. необходимо сделать shuffle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "out3-Yqj12kN"
      },
      "outputs": [],
      "source": [
        "def read_cancer_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_to_csv : str\n",
        "        Путь к cancer датасету.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.array\n",
        "        Матрица признаков опухолей.\n",
        "    y : np.array\n",
        "        Вектор бинарных меток, 1 соответствует доброкачественной опухоли (M),\n",
        "        0 --- злокачественной (B).\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(path_to_csv)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    y = df['label']\n",
        "    X = df.drop('label', axis=1)\n",
        "    y = y.replace('M', 1)\n",
        "    y = y.replace('B', 0)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def read_spam_dataset(path_to_csv: str) -> Tuple[np.array, np.array]:\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path_to_csv : str\n",
        "        Путь к spam датасету.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : np.array\n",
        "        Матрица признаков сообщений.\n",
        "    y : np.array\n",
        "        Вектор бинарных меток,\n",
        "        1 если сообщение содержит спам, 0 если не содержит.\n",
        "\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(path_to_csv)\n",
        "    df = df.sample(frac=1).reset_index(drop=True)\n",
        "    y = df['label']\n",
        "    X = df.drop('label', axis=1)\n",
        "\n",
        "    return np.array(X), np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYnqU3Qa12kN"
      },
      "outputs": [],
      "source": [
        "read_cancer_dataset(\"cancer.csv\")\n",
        "read_spam_dataset(\"spam.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYqbEsNZ12kO"
      },
      "source": [
        "### Задание 2  (1 балл)\n",
        "Начиная работать с данными, нам необходимо их предобработать и подготовить. В частности, нам необходимо разделить выборку на две: тренировочную и тестовую. Тренировочная выборка необходима для обучения алгоритма, а тестовая для проверки результатов обучения. Обычно используют коэффициент разделения `0.9`.\n",
        "\n",
        "Необходимо вернуть кортеж из `X_train`, `y_train`, `X_test` и `y_test`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zXRD_sM12kP"
      },
      "outputs": [],
      "source": [
        "def train_test_split(X: np.array, y: np.array, ratio: float) -> Tuple[np.array, np.array, np.array, np.array]:\n",
        "    \"\"\"\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : np.array\n",
        "        Матрица признаков.\n",
        "    y : np.array\n",
        "        Вектор меток.\n",
        "    ratio : float\n",
        "        Коэффициент разделения.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X_train : np.array\n",
        "        Матрица признаков для train выборки.\n",
        "    y_train : np.array\n",
        "        Вектор меток для train выборки.\n",
        "    X_test : np.array\n",
        "        Матрица признаков для test выборки.\n",
        "    y_test : np.array\n",
        "        Вектор меток для test выборки.\n",
        "\n",
        "    \"\"\"\n",
        "    size = X.shape[0]\n",
        "    delimiter = round(size * ratio)\n",
        "    return X[:delimiter], y[:delimiter], X[delimiter:], y[delimiter:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVS2HB7W12kQ"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Также прежде чем приступать к решению задачи, нам необходимо определиться с метриками, которые позволят нам оценить полученное решение. Для задач классификации мы можем использовать precision, recall и accuracy. Эти метрики считаются для каждого класса.\n",
        "\n",
        "Метод возвращает:\n",
        "\n",
        "* Вектор __Precision__, каждый из элементов которого равен значению метрики precision для соответствующего класса.\n",
        "\n",
        "* Вектор __Recall__, каждый из элементов которого равен значению метрики recall для соответствующего класса.\n",
        "\n",
        "* __Accuracy__ - число, которое равно отношению правильно классифицированных элементов выборке к размеру выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "810VTceU12kQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "65025cf8-fe6d-4239-c4c2-882375fcefe5"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2f044e639dc6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mcurrent_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_true_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
          ]
        }
      ],
      "source": [
        "pression, recall = [], []\n",
        "classes = np.unique(y_true)\n",
        "for i in range(len(classes)):\n",
        "  current_class = classes[i]\n",
        "  y_true_new = y_pred_new = [0] * len(y_true)\n",
        "  TP = FP = TN = FN = 0\n",
        "  for j in range(len(y_true)):\n",
        "    if y_true[j] == current_class:\n",
        "      y_true_new = 1\n",
        "    if y_pred[j] == current_class:\n",
        "      y_pred_new = 1\n",
        "  for k in range(len(y_true)):\n",
        "    if y_true_new == y_pred_new == 1:\n",
        "      TP += 1\n",
        "    elif y_true_new == y_pred_new == 0:\n",
        "      TN += 1\n",
        "    elif y_true_new != y_pred_new and y_true_new == 1:\n",
        "      FP += 1\n",
        "    elif y_true_new != y_pred_new and y_true_new == 0:\n",
        "      FN += 1\n",
        "  pression.append(TP/(TP + FP))\n",
        "  recall.append(TP/(TP + TN))\n",
        "accuracy = sum(y_true == y_pred) / y_pred\n",
        "return np.array(pression), np.array(recall), accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEeRNR7l12kR"
      },
      "source": [
        "Теперь, имея этот метод, мы можем построить кривые зависимости Precision, Recall и Accuracy от параметра `k`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aycxBoOE12kR"
      },
      "outputs": [],
      "source": [
        "def plot_precision_recall(X_train, y_train, X_test, y_test, max_k=30):\n",
        "    ks = list(range(1, max_k + 1))\n",
        "    classes = len(np.unique(list(y_train) + list(y_test)))\n",
        "    precisions = [[] for _ in range(classes)]\n",
        "    recalls = [[] for _ in range(classes)]\n",
        "    accuracies = []\n",
        "    for k in ks:\n",
        "        classifier = KNearest(k)\n",
        "        classifier.fit(X_train, y_train)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        precision, recall, acc = get_precision_recall_accuracy(y_pred, y_test)\n",
        "        for c in range(classes):\n",
        "            precisions[c].append(precision[c])\n",
        "            recalls[c].append(recall[c])\n",
        "        accuracies.append(acc)\n",
        "    def plot(x, ys, ylabel, legend=True):\n",
        "        plt.figure(figsize = (12, 3))\n",
        "        plt.xlabel(\"K\")\n",
        "        plt.ylabel(ylabel)\n",
        "        plt.xlim(x[0], x[-1])\n",
        "        plt.ylim(np.min(ys)-0.01, np.max(ys)+0.01)\n",
        "        for cls, cls_y in enumerate(ys):\n",
        "            plt.plot(x, cls_y, label=\"Class \" + str(cls))\n",
        "        if legend:\n",
        "            plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    plot(ks, recalls, \"Recall\")\n",
        "    plot(ks, precisions, \"Precision\")\n",
        "    plot(ks, [accuracies], \"Accuracy\", legend=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcjfOZtG12kR"
      },
      "source": [
        "Также для оценки качества классификации построим __ROC-кривую__. Она отражает зависимость __True Positive Rate__ (TPR) от __False Positive Rate__ (FPR) для заранее фиксированного класса. Чем график выше побочной диагонали - тем лучше."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKSur-jQ12kR"
      },
      "outputs": [],
      "source": [
        "def plot_roc_curve(X_train, y_train, X_test, y_test, max_k=30):\n",
        "    positive_samples = sum(1 for y in y_test if y == 0)\n",
        "    ks = list(range(1, max_k + 1))\n",
        "    curves_tpr = []\n",
        "    curves_fpr = []\n",
        "    colors = []\n",
        "    for k in ks:\n",
        "        colors.append([k / ks[-1], 0, 1 - k / ks[-1]])\n",
        "        knearest = KNearest(k)\n",
        "        knearest.fit(X_train, y_train)\n",
        "        p_pred = [p[0] for p in knearest.predict_proba(X_test)]\n",
        "        tpr = []\n",
        "        fpr = []\n",
        "        for w in np.arange(-0.01, 1.02, 0.01):\n",
        "            y_pred = [(0 if p > w else 1) for p in p_pred]\n",
        "            tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
        "            fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
        "        curves_tpr.append(tpr)\n",
        "        curves_fpr.append(fpr)\n",
        "    plt.figure(figsize = (7, 7))\n",
        "    for tpr, fpr, c in zip(curves_tpr, curves_fpr, colors):\n",
        "        plt.plot(fpr, tpr, color=c)\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
        "    plt.xlabel(\"False positive rate\")\n",
        "    plt.ylabel(\"True positive rate\")\n",
        "    plt.xlim(-0.01, 1.01)\n",
        "    plt.ylim(-0.01, 1.01)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lftibrh412kS"
      },
      "source": [
        "### Задание 4 (5 баллов)\n",
        "Теперь приступим к реализации классификатора. В этот раз будем использовать классификацию методом k средних. Поскольку основной решаемой задачий во время классификации этим методом является поиск ближайших соседей, а набор данных может быть достаточно большим, наивная реализация будет работать очень долго.\n",
        "\n",
        "Одним из способов решить эту проблему является __KD-дерево__. Оно позволяет значительно ускорить поиск ближайших соседей. Реализуйте построение KD-дерева и выполнение запросов на поиск k ближайших соседей.\n",
        "\n",
        "Метод `__init__` должен принимать на вход набор точек `X`, по которому будет строиться дерево, а так же размер листов `leaf_size` построенного дерева.\n",
        "\n",
        "Метод `query` должен принимать на вход набор точек `X`, для каждой из которых необходимо найти `k` ближайших соседей."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAgmYy2Z12kS"
      },
      "outputs": [],
      "source": [
        "class KDTree:\n",
        "    def __init__(self, X: np.array, leaf_size: int = 40):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.array\n",
        "            Набор точек, по которому строится дерево.\n",
        "        leaf_size : int\n",
        "            Минимальный размер листа\n",
        "            (то есть, пока возможно, пространство разбивается на области,\n",
        "            в которых не меньше leaf_size точек).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "\n",
        "        \"\"\"\n",
        "        self.leaf_size = leaf_size\n",
        "        self.idx = np.arange(len(X))\n",
        "        self.X_idx = np.array(list(zip(X, self.idx)), dtype=object)\n",
        "        self.tree = self.build_tree(self.X_idx)\n",
        "\n",
        "    def build_tree(self, points_idx, depth=0):\n",
        "        n = points_idx.shape[0]\n",
        "\n",
        "        if n > self.leaf_size:\n",
        "\n",
        "            axis = depth % points_idx.shape[1]\n",
        "\n",
        "            sorted_points_idx = sorted(points_idx, key=lambda point: point[0][axis])\n",
        "\n",
        "            return {'point': sorted_points_idx[n // 2],\n",
        "                    'left': self.build_tree(np.array(sorted_points_idx[:n // 2]), depth + 1),\n",
        "                    'right': self.build_tree(np.array(sorted_points_idx[n // 2 + 1:]), depth + 1)}\n",
        "\n",
        "        elif n >= 1:\n",
        "\n",
        "            return {'point': points_idx,\n",
        "                    'left': None,\n",
        "                    'right': None}\n",
        "\n",
        "    def merge(self, left, right):\n",
        "        len_left, len_right = len(left), len(right)\n",
        "        result = [0 for _ in range(len_left + len_right)]\n",
        "        pA = pB = pC = 0\n",
        "\n",
        "        while pA != len_left and pB != len_right:\n",
        "\n",
        "            if left[pA][0] <= right[pB][0]:\n",
        "                result[pC] = left[pA]\n",
        "                pC += 1\n",
        "                pA += 1\n",
        "            else:\n",
        "                result[pC] = right[pB]\n",
        "                pC += 1\n",
        "                pB += 1\n",
        "\n",
        "        while pA != len_left:\n",
        "            result[pC] = left[pA]\n",
        "            pC += 1\n",
        "            pA += 1\n",
        "\n",
        "        while pB != len_right:\n",
        "            result[pC] = right[pB]\n",
        "            pC += 1\n",
        "            pB += 1\n",
        "\n",
        "        return result\n",
        "\n",
        "    def compare_neighbours(self, distance_1, distance_2, k):\n",
        "        if distance_1 is not None:\n",
        "            distance_1 = sorted(distance_1, key=lambda x: x[0])\n",
        "        else:\n",
        "            distance_1 = []\n",
        "\n",
        "        if distance_2 is not None:\n",
        "            distance_2 = sorted(distance_2, key=lambda x: x[0])\n",
        "        else:\n",
        "            distance_2 = []\n",
        "\n",
        "        return self.merge(distance_1, distance_2)[:k]\n",
        "\n",
        "    def get_neighbours(self, tree, point_idx, k, depth=0):\n",
        "        if tree is None:\n",
        "            return None\n",
        "\n",
        "        axis = depth % len(point_idx)\n",
        "\n",
        "        if tree.get('left') is not None:\n",
        "\n",
        "            if point_idx[0][axis] < tree.get('point')[0][axis]:\n",
        "                next_tree = tree.get('left')\n",
        "                opposite_tree = tree.get('right')\n",
        "            else:\n",
        "                next_tree = tree.get('right')\n",
        "                opposite_tree = tree.get('left')\n",
        "\n",
        "            leaf_distance = [[np.linalg.norm(point_idx[0] - tree.get('point')[0]), tree.get('point')]]\n",
        "\n",
        "        else:\n",
        "            if point_idx[0][axis] < tree.get('point')[0][0][axis]:\n",
        "                next_tree = tree.get('left')\n",
        "                opposite_tree = tree.get('right')\n",
        "            else:\n",
        "                next_tree = tree.get('right')\n",
        "                opposite_tree = tree.get('left')\n",
        "\n",
        "            leaf_distance = [[np.linalg.norm(point_idx[0] - node_el[0]), node_el] for node_el in tree.get('point')]\n",
        "\n",
        "        distance_neighbours = self.compare_neighbours(self.get_neighbours(next_tree, point_idx, k, depth + 1),\n",
        "                                                      leaf_distance, k)\n",
        "\n",
        "        min_distance = distance_neighbours[-1][0]\n",
        "\n",
        "        if tree.get('left') is not None:\n",
        "            if min_distance > point_idx[0][axis] - tree.get('point')[0][axis]:\n",
        "                distance_neighbours = self.compare_neighbours(\n",
        "                    self.get_neighbours(opposite_tree, point_idx, k, depth + 1),\n",
        "                    distance_neighbours, k)\n",
        "        else:\n",
        "            if min_distance > point_idx[0][axis] - tree.get('point')[0][0][axis]:\n",
        "                distance_neighbours = self.compare_neighbours(\n",
        "                    self.get_neighbours(opposite_tree, point_idx, k, depth + 1),\n",
        "                    distance_neighbours, k)\n",
        "\n",
        "        return distance_neighbours\n",
        "\n",
        "    def query(self, X: np.array, k: int = 1):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.array\n",
        "            Набор точек, для которых нужно найти ближайших соседей.\n",
        "        k : int\n",
        "            Число ближайших соседей.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list[list]\n",
        "            Список списков (длина каждого списка k):\n",
        "            индексы k ближайших соседей для всех точек из X.\n",
        "\n",
        "        \"\"\"\n",
        "        ans = [[] for _ in range(len(X))]\n",
        "        for idx, point in enumerate(X):\n",
        "\n",
        "            for el in self.get_neighbours(self.tree, (point, idx), k):\n",
        "                ans[idx].append(el[1][1])\n",
        "\n",
        "        return ans\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX4xt3Fn12kS"
      },
      "source": [
        "Поскольку данная струкутра данных является сложной, ее стоит протестировать отдельно. Для этого проведем тестирование с небольшим набором случайных точек. Если после выполнение вывод пуст, то KD-дерево скорее всего работает правильно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3K5gFRW12kS"
      },
      "outputs": [],
      "source": [
        "def true_closest(X_train, X_test, k):\n",
        "    result = []\n",
        "    for x0 in X_test:\n",
        "        bests = list(sorted([(i, np.linalg.norm(x - x0)) for i, x in enumerate(X_train)], key=lambda x: x[1]))\n",
        "        bests = [i for i, d in bests]\n",
        "        result.append(bests[:min(k, len(bests))])\n",
        "    return result\n",
        "\n",
        "X_train = np.random.randn(100, 3)\n",
        "X_test = np.random.randn(10, 3)\n",
        "tree = KDTree(X_train, leaf_size=2)\n",
        "predicted = tree.query(X_test, k=4, return_distance=False)\n",
        "true = true_closest(X_train, X_test, k=4)\n",
        "\n",
        "if np.sum(np.abs(np.array(np.array(predicted).shape) - np.array(np.array(true).shape))) != 0:\n",
        "    print(\"Wrong shape\")\n",
        "else:\n",
        "    errors = sum([1 for row1, row2 in zip(predicted, true) for i1, i2 in zip(row1, row2) if i1 != i2])\n",
        "    if errors > 0:\n",
        "        print(\"Encounted\", errors, \"errors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU7oYFzL12kT"
      },
      "source": [
        "### Задание 5  (3 балла)\n",
        "Осталось реализовать сам классификатор. Реализуйте его, используя KD-дерево.\n",
        "\n",
        "Метод `__init__` принимает на вход количество соседей, по которым предсказывается класс, и размер листьев KD-дерева.\n",
        "\n",
        "Метод `fit` должен по набору данных и меток строить классификатор.\n",
        "\n",
        "Метод `predict_proba` должен предсказывать веротности классов для заданного набора данных основываясь на классах соседей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Fu8cnB12kT"
      },
      "outputs": [],
      "source": [
        "class KNearest:\n",
        "    def __init__(self, n_neighbors: int = 5, leaf_size: int = 30):\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_neighbors : int\n",
        "            Число соседей, по которым предсказывается класс.\n",
        "        leaf_size : int\n",
        "            Минимальный размер листа в KD-дереве.\n",
        "\n",
        "        \"\"\"\n",
        "        self.n_neighbors = n_neighbors\n",
        "        self.leaf_size = leaf_size\n",
        "\n",
        "    def fit(self, X: np.array, y: np.array):\n",
        "        self.tree = KDTree(X, self.leaf_size)\n",
        "        self.y = y\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.array\n",
        "            Набор точек, по которым строится классификатор.\n",
        "        y : np.array\n",
        "            Метки точек, по которым строится классификатор.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "    def predict_proba(self, X: np.array):\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.array\n",
        "            Набор точек, для которых нужно определить класс.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list[np.array]\n",
        "            Список np.array (длина каждого np.array равна числу классов):\n",
        "            вероятности классов для каждой точки X.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        neighbors = self.tree.query(X, self.n_neighbors)\n",
        "        count_clazz = np.unique(self.y).shape[0]\n",
        "        ans = [[0 for _ in range(count_clazz)] for _ in range(X.shape[0])]\n",
        "\n",
        "        for idx, neighbor in enumerate(neighbors):\n",
        "            for el in neighbor:\n",
        "                clazz = self.y[el]\n",
        "                ans[idx][clazz] += 1\n",
        "\n",
        "        for idx, el in enumerate(ans):\n",
        "            ans[idx] = [x / count_clazz for x in el]\n",
        "\n",
        "        return ans\n",
        "\n",
        "    def predict(self, X: np.array) -> np.array:\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : np.array\n",
        "            Набор точек, для которых нужно определить класс.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array\n",
        "            Вектор предсказанных классов.\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        return np.argmax(self.predict_proba(X), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwdaMbUb12kT"
      },
      "source": [
        "Наконец, протестируем наш классификатор на различных наборах данных. Реализация KNearest должна отработать за разумное время."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "7-uo_jK012kT"
      },
      "outputs": [],
      "source": [
        "X, y = read_cancer_dataset(\"cancer.csv\")\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, 0.9)\n",
        "plot_precision_recall(X_train, y_train, X_test, y_test)\n",
        "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "WiJWsaRa12kT"
      },
      "outputs": [],
      "source": [
        "X, y = read_spam_dataset(\"spam.csv\")\n",
        "X_train, y_train, X_test, y_test = train_test_split(X, y, 0.9)\n",
        "plot_precision_recall(X_train, y_train, X_test, y_test, max_k=20)\n",
        "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2HHx-eC12kT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}